# 错误解决

## 1.内核崩溃

当出现如下错误时，可以在头部添加这行代码：

```python
import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
```

![屏幕截图 2025-02-28 094808](https://typora-picture-wang.oss-cn-shanghai.aliyuncs.com/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-02-28%20094808.png)

## 2.%matplotlib inline

由于上述图片显示方法是jupyter notebook中的魔术方法，在pycharm中并不适用，为了在pycharm中也显示图像

可以删除这条语句后，改变为如下代码：

```python
import matplotlib.pyplot as plt
显示图像程序
plt.show()
```



## 3.argmax函数

`argmax` 是 NumPy 或 PyTorch 中常用的函数，用于返回张量（或数组）中指定轴上的最大值的索引。

```python
y_hat = 
[
    [0.1, 0.3, 0.6],  # 第一行：预测属于类别 2 的概率最高
    [0.8, 0.1, 0.1],  # 第二行：预测属于类别 0 的概率最高
    [0.2, 0.5, 0.3]   # 第三行：预测属于类别 1 的概率最高
]

# 输出结果：
[2, 0, 1]
```



## 4.torch.nn.Module

**1. 为什么要将 `net` 和 `torch.nn.Module` 进行比较？**

**(1) `torch.nn.Module` 是什么？**

`torch.nn.Module` 是 PyTorch 中所有神经网络的基类。

- 无论是自定义的深度学习模型，还是 PyTorch 提供的预定义模型（如 `torchvision.models` 下的模型），都继承自 `torch.nn.Module`。
- 它定义了模型的基本功能，例如参数管理、前向传播（`forward` 方法）等。

**(2) 为什么要检查 `net` 是否是 `torch.nn.Module` 的实例？**

在 PyTorch 中，只有 `torch.nn.Module` 类的对象支持 `eval()` 方法。
 `eval()` 方法用于将模型设置为评估模式（evaluation mode），即禁用一些只在训练模式下起作用的功能（如 `Dropout` 和 `BatchNorm` 的动态行为）。

通过 `isinstance(net, torch.nn.Module)` 判断：

- 如果 `net` 是一个 `torch.nn.Module` 对象
  - 调用 `net.eval()` 将模型切换到评估模式。
- 如果 `net` 不是 `torch.nn.Module` 对象
  - 说明 `net` 可能是其他类型的模型（例如自定义的非 PyTorch 模型），而这些模型可能没有 `eval()` 方法。为了避免错误调用，先进行类型检查。

------

**2. 为什么在评估时需要调用 `net.eval()`？**

`net.eval()` 是 PyTorch 中用于切换模型到评估模式的方法，它会影响某些层的行为，例如：

- **Dropout**：在评估模式下，Dropout 不起作用（即不随机丢弃神经元）。
- **Batch Normalization**：在评估模式下，BatchNorm 使用的是训练过程中记录的均值和方差，而不是当前批次的统计值。

**评估模式的目的**：

- 确保模型在评估时的行为与训练时有所区别，从而保证评估结果的稳定性和一致性。



## 5.numel()函数

**定义**

- **`numel`** 是 `number of elements` 的缩写。
- 它会计算张量中所有维度的元素总数。
- 本质上，`numel()` 就是将张量的所有维度相乘，得到张量的大小。



```python
x = torch.tensor([1, 2, 3, 4])  # 1 维张量，大小为 4
print(x.numel())  # 输出：4

x = torch.tensor([[1, 2], [3, 4], [5, 6]])  # 2 维张量，形状为 (3, 2)
print(x.numel())  # 输出：6

x = torch.ones(2, 3, 4)  # 3 维张量，形状为 (2, 3, 4)
print(x.numel())  # 输出：24
```





# 一.线性神经网路

## 1.线性回归从零开始实现

1.生成数据集：

我们使用线性模型参数$\mathbf{w} = [2, -3.4]^\top$、$b = 4.2$
和噪声项$\epsilon$生成数据集及其标签：$$\mathbf{y}= \mathbf{X} \mathbf{w} + b + \mathbf\epsilon.$$$\epsilon$可以视为模型预测和标签时的潜在观测误差。
在这里我们认为标准假设成立，即$\epsilon$服从均值为0的正态分布。为了简化问题，我们将标准差设为0.01。



2.训练过程：

概括一下，我们将执行以下循环：

* 初始化参数
* 重复以下训练，直到完成
    * 计算梯度$\mathbf{g} \leftarrow \partial_{(\mathbf{w},b)} \frac{1}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} l(\mathbf{x}^{(i)}, y^{(i)}, \mathbf{w}, b)$
    * 更新参数$(\mathbf{w}, b) \leftarrow (\mathbf{w}, b) - \eta \mathbf{g}$

在每个*迭代周期*（epoch）中，我们使用`data_iter`函数遍历整个数据集，并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。
这里的迭代周期个数`num_epochs`和学习率`lr`都是超参数，分别设为3和0.03。设置超参数很棘手，需要通过反复试验进行调整。



```python
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
# 如果没有这条语句，生成图片时会报错，因为numpy与torch组之间有OpenMP动态库冲突
import random
import torch
import matplotlib.pyplot as plt
from d2l import torch as d2l

# 随机生成数据函数
def synthetic_data(w, b, num_examples):  #@save
    """
    生成y=Xw+b+噪声
    :param w:真实的权重向量（权重系数）
    :param b:真实的偏置（截距）
    :param num_examples:生成的数据样本数量
    :return:X, y：返回输入特征矩阵 X 和目标值矩阵 y
    """
    X = torch.normal(0, 1, (num_examples, len(w)))
    """
        生成服从正态分布的随机张量。
    		mean=0：正态分布的均值为 0。
    		std=1：正态分布的标准差为 1。
    		size=(num_examples, len(w))：生成一个形状为 (num_examples, len(w)) 的张量，其中 num_examples 是样本数，
    		len(w) 是特征数（权重向量的长度）。
    	这里生成了一个随机矩阵 X，表示输入特征矩阵，每行是一个样本，每列是一个特征。
    """
    y = torch.matmul(X, w) + b
    """
    torch.matmul(X, w)：对矩阵 X 和向量 w 进行矩阵乘法，计算线性模型的预测值。
        X 是形状为 (num_examples, len(w)) 的矩阵，w 是形状为 (len(w),) 的向量。结果是一个形状为 (num_examples,) 的向量，
        表示每个样本的预测值。
        + b：为每个样本的预测值加上偏置 b（广播机制自动将标量 b 加到每个样本的预测值中）。
        y 是没有噪声的目标值。
    """
    y += torch.normal(0, 0.01, y.shape) #对数据y添加随机噪声
    return X, y.reshape((-1, 1))
    """
        y.reshape((-1, 1))：将 y 的形状调整为 (num_examples, 1)，即每个目标值作为一行，确保输出的形状符合线性回归的常见格式。
        -1 表示自动推断维度。
        例如，y 原本是形状 (num_examples,) 的向量，调整后变为 (num_examples, 1) 的矩阵。
        return X, y：返回输入特征矩阵 X 和目标值矩阵 y。
    """

# 从已有数据中，随机选取小批量数据并返回
def data_iter(batch_size, features, labels):
    """
    小批量随机采样迭代器
    :param batch_size:每个小批量的样本数量
    :param features: 原始输入数据输入X
    :param labels: 原始输出数据Y
    :return:batch_size大小的X和Y数据
    """
    num_examples = len(features)    #赋值数据X的行数
    indices = list(range(num_examples)) #生成0~X行数的数据索引，并转换为列表，这里生成0~999之间的索引
    # 这些样本是随机读取的，没有特定的顺序
    random.shuffle(indices)     #对列表进行打乱，确保采样顺序是随机的
    for i in range(0, num_examples, batch_size):
    # 以batch_size为步长，从0到num_examples之间进行遍历
        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])
        """
        从随机打乱的索引列表 indices 中取出当前批次的索引 batch_indices。
        i: min(i + batch_size, num_examples)：从第 i 个索引开始，取 batch_size 个样本。如果超出数据总数 num_examples，则取到末尾。
        torch.tensor(...)：将索引列表转换为 PyTorch 的张量格式，方便后续操作。
        """
        yield features[batch_indices], labels[batch_indices]
        """
        使用 yield 关键字返回一个生成器（generator），每次循环返回当前批次的特征和目标值：
        features[batch_indices]：从特征矩阵中提取当前批次的样本。
        labels[batch_indices]：从目标值张量中提取当前批次的目标值。
        yield 是 Python 的生成器特性，允许函数在每次调用时返回一个值，同时保持函数的状态，直到下一次调用。
        这个机制非常适合处理大规模数据集，因为它不会一次性将所有数据加载到内存中，而是按需生成小批量数据。
        """

# 定义线性回归模型函数 y=w*x+b
def linreg(X, w, b):  #@save
    """
    线性回归模型
    :param X: 原始数据X
    :param w: 训练w
    :param b: 训练b
    :return: 预测值y
    """
    return torch.matmul(X, w) + b

# 定义损失函数
def squared_loss(y_hat, y):  #@save
    """
    均方损失
    :param y_hat: 预测值y_hat
    :param y: 真实值y
    :return: 损失函数的值
    """
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2

# 小批量梯度下降实现
def sgd(params, lr, batch_size):  #@save
    """
    小批量梯度下降
    :param params: 传入参数w和b
    :param lr: 学习率
    :param batch_size: 数据个数
    :return: 无返回值，更新模型参数
    """
    # 禁用 PyTorch 的自动梯度计算功能
    with torch.no_grad():
        # 将参数读入param，并根据公式计算梯度
        for param in params:
            # 由于这里的-=是一个原地操作，所以会改变传入的param值
            # 如果使用的是param = param - ...,那么这是一个非原地操作，不会改变param的值
            param -= lr * param.grad / batch_size
            # 将参数的梯度清零，避免梯度积累
            param.grad.zero_()

# 设置原始数据的w= 2, 3.4 ，b= 4.2，生成1000个0~1之间服从正态分布的带噪声的数据
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)
# features是生成的(1000,2)的X数据，labels是生成的(1000,1)的Y数据

# 小批量选取数据测试
batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
# 从原始数据中，选取大小为batch_size的小批量数据，这里的X和y分别有10行，读取的是原始数据

# 这里生成的w和b是训练要用到的w和b，最后跟上方定义的真是w和b之间进行比较，看训练结果误差小不小
# 假设训练的w为服从正太分布的0~0,01之间的，size(2,1)2个输出维度1个输出维度的数据，启用 PyTorch 的自动微分功能，允许对 w 进行梯度计算。
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
# 生成一个形状为 (1,) 的张量，初始值为 0，启用自动微分功能，允许对 b 进行梯度计算
b = torch.zeros(1, requires_grad=True)

lr = 0.03           # 学习率
num_epochs = 3      # 训练次数
net = linreg        # 设置模型为线性
loss = squared_loss # 设置损失函数

for epoch in range(num_epochs):
    # 第一层for循环定义训练次数
    for X, y in data_iter(batch_size, features, labels):
        # 每次训练将原始数据乱序读入X和y
        # 将预测值和真实值给如损失函数
        l = loss(net(X, w, b), y)  # X和y的小批量损失
        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
        # 并以此计算关于[w,b]的梯度
        l.sum().backward()
        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
    # 禁用梯度计算，节省内存和计算资源
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')


print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```

输出结果为：

![image-20250228145401613](https://typora-picture-wang.oss-cn-shanghai.aliyuncs.com/image-20250228145401613.png)



## 2.线性回归的简洁实现

代码解析：

```python
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l

"""
使用 d2l.synthetic_data 函数生成一组模拟的线性回归数据。
这个函数会根据以下公式生成数据：y=Xw+b+ϵ
    X 是特征矩阵（随机生成）。
    w 是权重向量（这里为 [2, -3.4]）。
    b 是偏置（这里为 4.2）。
    ϵ 是一个服从正态分布的噪声，用于模拟真实数据的随机性。
"""
# 生成原始数据
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)

"""下面这段代码：
1.定义了一个函数 load_array，通过 PyTorch 的 TensorDataset 和 DataLoader 封装数据。
2.使用 load_array 函数构造了一个数据迭代器 data_iter，按批次读取特征和标签。
3.使用 next(iter(data_iter)) 查看数据迭代器中的第一个批次内容。
"""

# 数据迭代器，返回小批量数据
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """
    该函数用于将数据集封装为 PyTorch 中的 数据迭代器（DataLoader），以便后续根据批量（batch）大小读取数据
    :param data_arrays: 包含特征和标签的元组，例如 (features, labels)
    :param batch_size: 每次从数据集中取出的样本数量（批量大小）
    :param is_train: 布尔值，表示是否是训练模式。如果为 True，数据会被随机打乱;如果为False，数据按顺序加载
    :return: 数据迭代器，返回小批量数据
    """
    # 将输入数据封装到 PyTorch 的 TensorDataset 中
    dataset = data.TensorDataset(*data_arrays)
    # 将封装的数据传入 DataLoader，并设置批量大小和是否打乱
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
# 获取 data_iter 中的第一个批次数据
next(iter(data_iter))

# nn是神经网络的缩写
from torch import nn
"""
torch.nn 是 PyTorch 中的神经网络模块，提供了构建神经网络所需的各种工具。
这里我们使用了 nn.Sequential 和 nn.Linear。
"""
net = nn.Sequential(nn.Linear(2, 1))
"""
nn.Sequential 是 PyTorch 中用于快速搭建网络的容器。它按照定义的顺序将多个层串联起来。
这里 nn.Linear(2, 1) 是一个全连接层（线性层），表示输入有 2 个特征，输出有 1 个特征。
net 是一个简单的线性回归模型，公式为：y=Xw+b
    X: 输入特征，形状为 (batch_size, 2)。
    w: 权重，形状为 (2, 1)。
    b: 偏置，形状为 (1)。
"""

net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
"""
初始化权重：normal_(0, 0.01) 将权重初始化为服从均值为 0、标准差为 0.01 的正态分布。
          避免权重过大或过小影响训练收敛。
初始化偏置：fill_(0) 将偏置初始化为全 0。
"""

loss = nn.MSELoss()
"""
nn.MSELoss 是 PyTorch 中的均方误差（Mean Squared Error, MSE）损失函数。
"""
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
"""
优化器:
    PyTorch 提供了多种优化器，这里使用的是随机梯度下降（Stochastic Gradient Descent, SGD）。
    torch.optim.SGD 是 PyTorch 的 SGD 优化器。
参数:
    net.parameters():
        net.parameters() 返回模型中所有需要训练的参数（权重和偏置）。
        这里包括 net[0].weight 和 net[0].bias。
    lr=0.03:
        学习率（Learning Rate），决定每次参数更新的步长
"""

num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y) # 计算损失
        trainer.zero_grad() # 梯度清零
        l.backward()        # 反向传播
        trainer.step()      # 参数更新
    l = loss(net(features), labels) # 计算整个数据集上的损失
    print(f'epoch {epoch + 1}, loss {l:f}')

w = net[0].weight.data
print('w的估计误差：', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('b的估计误差：', true_b - b)
```

## 3.图像分类数据集

代码实现：

```python
import matplotlib.pyplot as plt
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l
import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"

# 设置图像显示为 SVG 格式。SVG 是矢量图格式，显示图像会更清晰。
d2l.use_svg_display()

# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
# 并除以255使得所有像素的数值均在0～1之间
# FashionMNIST 是一个常用的图像分类基准数据集。每张图像是 28×28 的灰度图像，共 10 个类别（如 T 恤、鞋子、包等）。
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)

# 输出训练集和测试集的样本数量
print(len(mnist_train), len(mnist_test))
print(mnist_train[0][0].shape)

def get_fashion_mnist_labels(labels):  #@save
    """
    返回Fashion-MNIST数据集的文本标签
    :param labels: 一个数值标签的列表或张量
    :return:根据传入的标签数字，返回对应的名字组成的列表
    """
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    # 这是一个列表推导式，将输入中的标签i转换为对应的文本标签
    return [text_labels[int(i)] for i in labels]

def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """
    绘制图像列表
    :param imgs:要显示的图像列表（可以是张量或 PIL 图像）
    :param num_rows:图像显示的行数
    :param num_cols:图像显示的列数
    :param titles:每张图像的标题列表，可选
    :param scale:调整显示图像的整体缩放比例
    :return:
    """
    # 计算绘图窗口的大小，宽度由列数（num_cols）乘以比例 scale 决定，高度由行数（num_rows）乘以比例 scale 决定
    figsize = (num_cols * scale, num_rows * scale)
    """
    使用 matplotlib 的 subplots 方法创建一个包含多个子图的网格（num_rows × num_cols）。
    返回的 axes 是一个包含所有子图的数组（或二维数组）。
    _ 用于接收不需要的返回值（如 Figure 对象）。
    """
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    # 将二维数组 axes 展平为一维数组，方便后续逐一处理每个子图。
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        """
        if作用：如果img是tensor张量类型，则转为numpy类型再显示；如果是PIL图像，则直接显示
        """
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:
            # PIL图片
            ax.imshow(img)
            # 隐藏x坐标轴和y坐标轴
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        # 为图像命名标题
        if titles:
            ax.set_title(titles[i])
    return axes

# X：小批量提取的当前图像张量，形状为[18,1,28,28]
# y：小批量选取的图像都有自己的标签，这些标签组成的张量就是y，形状为[18]
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
"""
X。reshape:调整形状为[18,28,28]，去掉通道维度以便于绘图
imgs=X.reshape(18, 28, 28)：要显示的图像。
num_rows=2, num_cols=9：将 18 张图像以 2 行 9 列的网格显示。
titles=get_fashion_mnist_labels(y)：获取图像对应的文本标签，作为标题。
"""
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
plt.show()

batch_size = 256

def get_dataloader_workers():  #@save
    """使用4个进程来读取数据"""
    return 4
"""
mnist_train：
    数据集对象，包含训练数据（之前用 torchvision.datasets.FashionMNIST 加载的训练集）。
batch_size：
    每次从数据集中加载的样本数量（批量大小）。
shuffle=True：
    设置为 True 表示在每个 epoch（训练周期）开始时，随机打乱数据集中的样本顺序。
    数据随机化能够提高模型的泛化能力，避免模型过于依赖数据的顺序模式。
num_workers=get_dataloader_workers()：
    调用了之前定义的函数 get_dataloader_workers，设置 num_workers = 4，即使用 4 个进程并行加载数据。
返回值 train_iter：
    数据加载器 train_iter 是一个可迭代对象，它会在每次迭代中返回一个批量的数据（X，y）：
    X：批量的输入图像数据（形状为 [batch_size, channels, height, width]）。
    y：批量的标签数据（形状为 [batch_size]）。
"""

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
                             num_workers=get_dataloader_workers())
"""
d2l.Timer 是 d2l 库提供的一个计时工具，用于测量代码运行的时间。
作用：
    创建一个计时器对象 timer，可以通过调用其方法（如 start 和 stop）来记录时间。
"""
timer = d2l.Timer()
"""
遍历 train_iter：
    train_iter 是一个数据加载器对象，能够逐批次返回数据。
循环内部：
    每次迭代都会将一个批量的数据加载到变量 X 和 y 中：
    X：当前批次的输入图像（张量）。
    y：当前批次的标签（张量）。
continue：这里的循环体没有进行任何操作，仅用于测试加载数据的时间。

"""
for X, y in train_iter:
    continue
# 输出加载数据所需时间
print(f'{timer.stop():.2f} sec')

def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """
    下载Fashion-MNIST数据集，然后将其加载到内存中
    :param batch_size: 批量大小，即每次迭代加载的数据量
    :param resize: (可选)，如果指定resize，则将图像调整为指定的大小(如64x64)
    :return:返回一个元组，包含训练集和测试集的数据加载器
    """

    """
    定义对数据的预处理操作
    transforms.ToTensor()：
        将图像由 PIL.Image 或 numpy.ndarray 转换为 PyTorch 的 Tensor 格式。
        同时将像素值从 [0, 255] 归一化到 [0, 1]。
    transforms.Resize(resize)（可选）：
        如果指定了 resize，将图像调整为给定大小（如 64×64）。
        使用 trans.insert(0, ...) 将此操作插入到预处理列表的最前面。
    transforms.Compose(trans)：
        将上述预处理操作组合成一个管道，依次对图像应用这些操作。
    """
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)

    # 下载数据集
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)

    """
    使用Pytorch的DataLoader为训练集和测试集创建数据加载器
    mnist_train 和 mnist_test：
        数据加载器的输入数据集。
    batch_size：
        指定每次加载的样本数量。
    shuffle=True / False：
        shuffle=True：随机打乱训练数据（适用于训练集）。
        shuffle=False：不打乱数据（适用于测试集）。
    num_workers=get_dataloader_workers()：
        设置加载数据时的工作进程数（之前定义的函数 get_dataloader_workers 返回 4）。
    函数返回一个元组，包含训练集和测试集的数据加载器。
    """
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))

"""
调用 load_data_fashion_mnist 函数，加载训练集和测试集的数据加载器。
    batch_size=32：每次加载 32 张图像。
    resize=64：将图像调整为 64×64 的分辨率。
返回值：
    train_iter：训练集的数据加载器。
    test_iter：测试集的数据加载器。
"""
train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
for X, y in train_iter:
    # 打印当前批次输入数据 X 和标签 y 的形状和数据类型。
    print(X.shape, X.dtype, y.shape, y.dtype)
    break
```



## 4.Softmax的从零实现

1.`y_hat` 的每一行代表 **一个样本的预测结果**。

- 假设有 `N` 个样本和 `C` 个类别，那么 `y_hat` 是一个形状为 `(N, C)` 的二维张量。
- 每一行是一个长度为 `C` 的向量，表示该样本属于每个类别的概率分布（经过 Softmax 函数处理后）。

```python
y_hat = [
    [0.1, 0.3, 0.6],  # 第一行，表示样本 1 的预测概率
    [0.8, 0.1, 0.1],  # 第二行，表示样本 2 的预测概率
    [0.2, 0.5, 0.3]   # 第三行，表示样本 3 的预测概率
]
```

- 第一行 `[0.1, 0.3, 0.6]` 表示第一个样本被预测为属于类别 0、类别 1 和类别 2 的概率分别为 0.1、0.3 和 0.6。
- 同理，第二行和第三行分别表示样本 2 和样本 3 的预测概率。

总结：**每一行表示一个样本的预测结果，是一个概率分布。**

**Softmax 的特点与约束**

1. **每一行的概率和为 1**：
   - Softmax 函数将模型的原始输出（logits）变换为一个概率分布，因此每一行的所有值加起来等于 1。
2. **每一列的值表示不同样本对该类别的预测概率**：
   - 某一列中不同的值反映了不同样本对该类别的置信度。

2.数据含义：每个图像大小为28*28，共有十种类别

```python
x=(batch_size，784)# 每一行是单个样本的数据信息
w=[784，10] # 有十组w，每组有784个数据，每一列是一组张量
b=[1，10] # 有十组b，每组只加1个b，每一列是一组张量

y_hat=(batch_size,10) 
# 每一行是一次预测的结果，每行之和为1
# 每行的每列是对应类别的概率

x.sum(0)按列求和  x.sum(1)按行求和
```



# 二.多层感知机



